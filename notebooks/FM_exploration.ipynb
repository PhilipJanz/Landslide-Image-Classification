{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "# Add the src directory to the Python path\n",
        "sys.path.append(str(Path().resolve().parent / \"src\"))\n",
        "\n",
        "import config\n",
        "from config import FM_MODEL_DIR\n",
        "from model.train import LandslideDataset\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
        "\n",
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "# --- Configuration ---\n",
        "# Define the path to your downloaded model file\n",
        "# Make sure to replace 'B13_vitb16_fgmae_ep99.pth' with the actual path if it's different.\n",
        "model_path = FM_MODEL_DIR / 'reBEN_resnet18-all-v0.2.0'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(12, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act1): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (drop_path): DropPath(drop_prob=0.021)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (drop_path): DropPath(drop_prob=0.043)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (drop_path): DropPath(drop_prob=0.064)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (drop_path): DropPath(drop_prob=0.086)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (drop_path): DropPath(drop_prob=0.107)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (drop_path): DropPath(drop_prob=0.129)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (drop_path): DropPath(drop_prob=0.150)\n",
              "    )\n",
              "  )\n",
              "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "  (fc): Linear(in_features=512, out_features=19, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cell 2: Load ViT-B/16 Architecture\n",
        "model = torch.load(model_path, weights_only=False)\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet                                   [1, 19]                   --\n",
              "├─Conv2d: 1-1                            [1, 64, 60, 60]           37,632\n",
              "├─BatchNorm2d: 1-2                       [1, 64, 60, 60]           128\n",
              "├─ReLU: 1-3                              [1, 64, 60, 60]           --\n",
              "├─MaxPool2d: 1-4                         [1, 64, 30, 30]           --\n",
              "├─Sequential: 1-5                        [1, 64, 30, 30]           --\n",
              "│    └─BasicBlock: 2-1                   [1, 64, 30, 30]           --\n",
              "│    │    └─Conv2d: 3-1                  [1, 64, 30, 30]           36,864\n",
              "│    │    └─BatchNorm2d: 3-2             [1, 64, 30, 30]           128\n",
              "│    │    └─Identity: 3-3                [1, 64, 30, 30]           --\n",
              "│    │    └─ReLU: 3-4                    [1, 64, 30, 30]           --\n",
              "│    │    └─Identity: 3-5                [1, 64, 30, 30]           --\n",
              "│    │    └─Conv2d: 3-6                  [1, 64, 30, 30]           36,864\n",
              "│    │    └─BatchNorm2d: 3-7             [1, 64, 30, 30]           128\n",
              "│    │    └─ReLU: 3-8                    [1, 64, 30, 30]           --\n",
              "│    └─BasicBlock: 2-2                   [1, 64, 30, 30]           --\n",
              "│    │    └─Conv2d: 3-9                  [1, 64, 30, 30]           36,864\n",
              "│    │    └─BatchNorm2d: 3-10            [1, 64, 30, 30]           128\n",
              "│    │    └─Identity: 3-11               [1, 64, 30, 30]           --\n",
              "│    │    └─ReLU: 3-12                   [1, 64, 30, 30]           --\n",
              "│    │    └─Identity: 3-13               [1, 64, 30, 30]           --\n",
              "│    │    └─Conv2d: 3-14                 [1, 64, 30, 30]           36,864\n",
              "│    │    └─BatchNorm2d: 3-15            [1, 64, 30, 30]           128\n",
              "│    │    └─DropPath: 3-16               [1, 64, 30, 30]           --\n",
              "│    │    └─ReLU: 3-17                   [1, 64, 30, 30]           --\n",
              "├─Sequential: 1-6                        [1, 128, 15, 15]          --\n",
              "│    └─BasicBlock: 2-3                   [1, 128, 15, 15]          --\n",
              "│    │    └─Conv2d: 3-18                 [1, 128, 15, 15]          73,728\n",
              "│    │    └─BatchNorm2d: 3-19            [1, 128, 15, 15]          256\n",
              "│    │    └─Identity: 3-20               [1, 128, 15, 15]          --\n",
              "│    │    └─ReLU: 3-21                   [1, 128, 15, 15]          --\n",
              "│    │    └─Identity: 3-22               [1, 128, 15, 15]          --\n",
              "│    │    └─Conv2d: 3-23                 [1, 128, 15, 15]          147,456\n",
              "│    │    └─BatchNorm2d: 3-24            [1, 128, 15, 15]          256\n",
              "│    │    └─DropPath: 3-25               [1, 128, 15, 15]          --\n",
              "│    │    └─Sequential: 3-26             [1, 128, 15, 15]          8,448\n",
              "│    │    └─ReLU: 3-27                   [1, 128, 15, 15]          --\n",
              "│    └─BasicBlock: 2-4                   [1, 128, 15, 15]          --\n",
              "│    │    └─Conv2d: 3-28                 [1, 128, 15, 15]          147,456\n",
              "│    │    └─BatchNorm2d: 3-29            [1, 128, 15, 15]          256\n",
              "│    │    └─Identity: 3-30               [1, 128, 15, 15]          --\n",
              "│    │    └─ReLU: 3-31                   [1, 128, 15, 15]          --\n",
              "│    │    └─Identity: 3-32               [1, 128, 15, 15]          --\n",
              "│    │    └─Conv2d: 3-33                 [1, 128, 15, 15]          147,456\n",
              "│    │    └─BatchNorm2d: 3-34            [1, 128, 15, 15]          256\n",
              "│    │    └─DropPath: 3-35               [1, 128, 15, 15]          --\n",
              "│    │    └─ReLU: 3-36                   [1, 128, 15, 15]          --\n",
              "├─Sequential: 1-7                        [1, 256, 8, 8]            --\n",
              "│    └─BasicBlock: 2-5                   [1, 256, 8, 8]            --\n",
              "│    │    └─Conv2d: 3-37                 [1, 256, 8, 8]            294,912\n",
              "│    │    └─BatchNorm2d: 3-38            [1, 256, 8, 8]            512\n",
              "│    │    └─Identity: 3-39               [1, 256, 8, 8]            --\n",
              "│    │    └─ReLU: 3-40                   [1, 256, 8, 8]            --\n",
              "│    │    └─Identity: 3-41               [1, 256, 8, 8]            --\n",
              "│    │    └─Conv2d: 3-42                 [1, 256, 8, 8]            589,824\n",
              "│    │    └─BatchNorm2d: 3-43            [1, 256, 8, 8]            512\n",
              "│    │    └─DropPath: 3-44               [1, 256, 8, 8]            --\n",
              "│    │    └─Sequential: 3-45             [1, 256, 8, 8]            33,280\n",
              "│    │    └─ReLU: 3-46                   [1, 256, 8, 8]            --\n",
              "│    └─BasicBlock: 2-6                   [1, 256, 8, 8]            --\n",
              "│    │    └─Conv2d: 3-47                 [1, 256, 8, 8]            589,824\n",
              "│    │    └─BatchNorm2d: 3-48            [1, 256, 8, 8]            512\n",
              "│    │    └─Identity: 3-49               [1, 256, 8, 8]            --\n",
              "│    │    └─ReLU: 3-50                   [1, 256, 8, 8]            --\n",
              "│    │    └─Identity: 3-51               [1, 256, 8, 8]            --\n",
              "│    │    └─Conv2d: 3-52                 [1, 256, 8, 8]            589,824\n",
              "│    │    └─BatchNorm2d: 3-53            [1, 256, 8, 8]            512\n",
              "│    │    └─DropPath: 3-54               [1, 256, 8, 8]            --\n",
              "│    │    └─ReLU: 3-55                   [1, 256, 8, 8]            --\n",
              "├─Sequential: 1-8                        [1, 512, 4, 4]            --\n",
              "│    └─BasicBlock: 2-7                   [1, 512, 4, 4]            --\n",
              "│    │    └─Conv2d: 3-56                 [1, 512, 4, 4]            1,179,648\n",
              "│    │    └─BatchNorm2d: 3-57            [1, 512, 4, 4]            1,024\n",
              "│    │    └─Identity: 3-58               [1, 512, 4, 4]            --\n",
              "│    │    └─ReLU: 3-59                   [1, 512, 4, 4]            --\n",
              "│    │    └─Identity: 3-60               [1, 512, 4, 4]            --\n",
              "│    │    └─Conv2d: 3-61                 [1, 512, 4, 4]            2,359,296\n",
              "│    │    └─BatchNorm2d: 3-62            [1, 512, 4, 4]            1,024\n",
              "│    │    └─DropPath: 3-63               [1, 512, 4, 4]            --\n",
              "│    │    └─Sequential: 3-64             [1, 512, 4, 4]            132,096\n",
              "│    │    └─ReLU: 3-65                   [1, 512, 4, 4]            --\n",
              "│    └─BasicBlock: 2-8                   [1, 512, 4, 4]            --\n",
              "│    │    └─Conv2d: 3-66                 [1, 512, 4, 4]            2,359,296\n",
              "│    │    └─BatchNorm2d: 3-67            [1, 512, 4, 4]            1,024\n",
              "│    │    └─Identity: 3-68               [1, 512, 4, 4]            --\n",
              "│    │    └─ReLU: 3-69                   [1, 512, 4, 4]            --\n",
              "│    │    └─Identity: 3-70               [1, 512, 4, 4]            --\n",
              "│    │    └─Conv2d: 3-71                 [1, 512, 4, 4]            2,359,296\n",
              "│    │    └─BatchNorm2d: 3-72            [1, 512, 4, 4]            1,024\n",
              "│    │    └─DropPath: 3-73               [1, 512, 4, 4]            --\n",
              "│    │    └─ReLU: 3-74                   [1, 512, 4, 4]            --\n",
              "├─SelectAdaptivePool2d: 1-9              [1, 512]                  --\n",
              "│    └─AdaptiveAvgPool2d: 2-9            [1, 512, 1, 1]            --\n",
              "│    └─Flatten: 2-10                     [1, 512]                  --\n",
              "├─Linear: 1-10                           [1, 19]                   9,747\n",
              "==========================================================================================\n",
              "Total params: 11,214,483\n",
              "Trainable params: 11,214,483\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 654.61\n",
              "==========================================================================================\n",
              "Input size (MB): 0.69\n",
              "Forward/backward pass size (MB): 11.64\n",
              "Params size (MB): 44.86\n",
              "Estimated Total Size (MB): 57.19\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "# Example input size for ViT: (batch_size, channels, height, width)\n",
        "summary(model, input_size=(1, 12, 120, 120))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LandslideDataset(Dataset):\n",
        "    \"\"\"Dataset for loading processed landslide detection images - loads all data into memory.\"\"\"\n",
        "    \n",
        "    def __init__(self, image_dir, csv_path, transform=None, device=\"cpu\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_dir: Directory containing processed .npy files\n",
        "            csv_path: Path to CSV file with image IDs and labels\n",
        "            transform: Optional transform to apply to images\n",
        "            device: Device to load data onto (\"cpu\" or \"cuda\")\n",
        "        \"\"\"\n",
        "        self.image_dir = Path(image_dir)\n",
        "        self.transform = transform\n",
        "        self.device = device\n",
        "        \n",
        "        # Load CSV data\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.image_ids = self.df['ID'].values\n",
        "        self.labels = self.df['label'].values.astype(np.float32)\n",
        "        \n",
        "        # Load all images into memory at once\n",
        "        self.images = []\n",
        "        self.valid_indices = []\n",
        "        \n",
        "        for i, img_id in enumerate(tqdm(self.image_ids, desc=\"Loading images\")):\n",
        "            img_path = self.image_dir / f\"{img_id}.npy\"\n",
        "            if img_path.exists():\n",
        "                # Load image and convert to tensor\n",
        "                image = np.load(img_path).astype(np.float32)\n",
        "                image = torch.from_numpy(image).permute(2, 0, 1)  # (C, H, W)\n",
        "                \n",
        "                # Move to device if specified\n",
        "                if device != \"cpu\":\n",
        "                    image = image.to(device)\n",
        "                \n",
        "                self.images.append(image)\n",
        "                self.valid_indices.append(i)\n",
        "            else:\n",
        "                print(f\"Warning: {img_path} not found\")\n",
        "        \n",
        "        print(f\"Loaded {len(self.valid_indices)} valid images out of {len(self.image_ids)}\")\n",
        "        print(f\"Total memory usage: {sum(img.element_size() * img.nelement() for img in self.images) / 1024**3:.2f} GB\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.valid_indices)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # Get valid index\n",
        "        valid_idx = self.valid_indices[idx]\n",
        "        label = self.labels[valid_idx]\n",
        "        image = self.images[idx]  # Already loaded in memory\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # Get valid index\n",
        "        valid_idx = self.valid_indices[idx]\n",
        "        label = self.labels[valid_idx]\n",
        "        image = self.images[idx]  # Already loaded in memory\n",
        "\n",
        "        # Create a 12-channel zero tensor\n",
        "        img_12ch = torch.zeros((12, image.shape[1], image.shape[2]), dtype=image.dtype)\n",
        "\n",
        "        # Define mapping from your 6 bands to model input bands\n",
        "        band_map = {\n",
        "            0: 3,\n",
        "            1: 2,\n",
        "            2: 1,\n",
        "            3: 7,\n",
        "            4: 11,\n",
        "            5: 10\n",
        "        }\n",
        "\n",
        "        for src_idx, dst_idx in band_map.items():\n",
        "            img_12ch[dst_idx] = image[src_idx]\n",
        "\n",
        "        # Apply optional transform (e.g., resizing)\n",
        "        if self.transform:\n",
        "            img_12ch = self.transform(img_12ch)\n",
        "\n",
        "        return img_12ch, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset into memory...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading images: 100%|██████████| 7147/7147 [00:55<00:00, 127.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 7147 valid images out of 7147\n",
            "Total memory usage: 1.31 GB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create dataset with data loaded into memory\n",
        "print(\"Loading dataset into memory...\")\n",
        "dataset = LandslideDataset(\n",
        "    image_dir=config.PROCESSED_TRAIN_IMAGE_DIR,\n",
        "    csv_path=config.TRAIN_CSV_PATH,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "dataset.transform = v2.Resize(size=120)\n",
        "\n",
        "data_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    generator=torch.Generator().manual_seed(config.SEED)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten(xss):\n",
        "    return [x for xs in xss for x in xs]\n",
        "all_targets = []\n",
        "class_preds = []\n",
        "for batch_idx, (images, targets) in enumerate(data_loader):\n",
        "    all_targets.append(targets.numpy())\n",
        "    \n",
        "    output = model(images.to(device))\n",
        "    preds = [np.argmax(x) for x in output.cpu().data.numpy()]\n",
        "    class_preds.append(preds)\n",
        "\n",
        "all_targets = np.concatenate(all_targets)\n",
        "class_preds = np.array(flatten(class_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({np.int64(1): 440,\n",
              "         np.int64(17): 178,\n",
              "         np.int64(3): 141,\n",
              "         np.int64(12): 140,\n",
              "         np.int64(6): 134,\n",
              "         np.int64(8): 72,\n",
              "         np.int64(5): 42,\n",
              "         np.int64(15): 36,\n",
              "         np.int64(10): 30,\n",
              "         np.int64(18): 19,\n",
              "         np.int64(11): 9,\n",
              "         np.int64(7): 9,\n",
              "         np.int64(13): 3,\n",
              "         np.int64(9): 1,\n",
              "         np.int64(14): 1})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(class_preds[all_targets == 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({np.int64(1): 1783,\n",
              "         np.int64(12): 926,\n",
              "         np.int64(17): 761,\n",
              "         np.int64(6): 744,\n",
              "         np.int64(3): 490,\n",
              "         np.int64(8): 293,\n",
              "         np.int64(18): 286,\n",
              "         np.int64(10): 169,\n",
              "         np.int64(15): 135,\n",
              "         np.int64(5): 135,\n",
              "         np.int64(11): 78,\n",
              "         np.int64(9): 46,\n",
              "         np.int64(13): 23,\n",
              "         np.int64(7): 15,\n",
              "         np.int64(16): 5,\n",
              "         np.int64(14): 2,\n",
              "         np.int64(0): 1})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(class_preds[all_targets == 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove classification layer:\n",
        "model.fc = nn.Identity()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_mtx = []\n",
        "for batch_idx, (images, targets) in enumerate(data_loader):\n",
        "    output = model(images.to(device))\n",
        "    embedding_mtx.append(output.cpu().data.numpy())\n",
        "embedding_mtx = np.concatenate(embedding_mtx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=8, random_state=0, n_init=\"auto\").fit_predict(embedding_mtx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({np.int32(1): 3110, np.int32(5): 954, np.int32(3): 821, np.int32(2): 748, np.int32(6): 666, np.int32(4): 397, np.int32(7): 252, np.int32(0): 199})\n",
            "Counter({np.int32(1): 715, np.int32(5): 162, np.int32(6): 161, np.int32(3): 127, np.int32(0): 59, np.int32(7): 30, np.int32(2): 1})\n"
          ]
        }
      ],
      "source": [
        "print(Counter(kmeans))\n",
        "print(Counter(kmeans[all_targets == 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['ID_81CCTX', 'ID_K7DZF2', 'ID_THLFOS', 'ID_HXP5ML', 'ID_Z6MT2M',\n",
              "       'ID_KAE13A', 'ID_PUZLZB', 'ID_K75Q1F', 'ID_1Q4AOO', 'ID_R4XKHT',\n",
              "       'ID_R6I7Z5', 'ID_8XU9PK', 'ID_3OW9N3', 'ID_K3BMDJ', 'ID_29RVBQ',\n",
              "       'ID_IK14T0', 'ID_PCT6XN', 'ID_OQP2JZ', 'ID_69AWCF', 'ID_9DB1U9',\n",
              "       'ID_SV2JH6', 'ID_JRVM9X', 'ID_IELG8M', 'ID_JJRTOB', 'ID_OXHKIL',\n",
              "       'ID_Y53668', 'ID_QZJO8B', 'ID_6481LY', 'ID_Q1KVLC', 'ID_O9KSMX',\n",
              "       'ID_8GUH5A', 'ID_E66YLO', 'ID_S6UVD7', 'ID_EN6LWL', 'ID_8K8LZN',\n",
              "       'ID_V62VPV', 'ID_JGIF2L', 'ID_M5AOEF', 'ID_030E20', 'ID_8NQ8MY',\n",
              "       'ID_7K66L0', 'ID_V1LZYY', 'ID_SDP8AJ', 'ID_A9PB6J', 'ID_E6KKIQ',\n",
              "       'ID_40KZ27', 'ID_KNHNZ3', 'ID_7VUJ7O', 'ID_CPPZ3T', 'ID_AUSMPY',\n",
              "       'ID_BOSI3L', 'ID_K45WOE', 'ID_CHF8N2', 'ID_O7LSKU', 'ID_LM08R7',\n",
              "       'ID_OUG1MA', 'ID_M8RTRC', 'ID_JKJ7X1', 'ID_5NZDM6', 'ID_2758EP',\n",
              "       'ID_TTPIYG', 'ID_UHHZES', 'ID_I6GD66', 'ID_OYZQCC', 'ID_5B2Q7W',\n",
              "       'ID_NJ69O3', 'ID_K428U7', 'ID_HMSG74', 'ID_FFMBFC', 'ID_Q3HTFK',\n",
              "       'ID_J59GIH', 'ID_JXQUYT', 'ID_O8Y927', 'ID_7KRJ54', 'ID_15F6H8',\n",
              "       'ID_S7A0OG', 'ID_O0XMJV', 'ID_T84LO7', 'ID_FAGFTA', 'ID_F1OXNQ',\n",
              "       'ID_FWT4FW', 'ID_SGXWC1', 'ID_MHU5LH', 'ID_SS1SZX', 'ID_BUVFWD',\n",
              "       'ID_6E52YZ', 'ID_5RMSFN', 'ID_QS59KW', 'ID_2U0ARI', 'ID_JMLRCT',\n",
              "       'ID_V8WRTQ', 'ID_3KFTH0', 'ID_7IFOWI', 'ID_5T4UNE', 'ID_10YPP4',\n",
              "       'ID_OQJ1ZZ', 'ID_KW3MBI', 'ID_VFXTKH', 'ID_W7280F', 'ID_C4S39T',\n",
              "       'ID_H9ZCUG', 'ID_5E2HO9', 'ID_6XTGX2', 'ID_JEHFWJ', 'ID_D4AKL4',\n",
              "       'ID_445F95', 'ID_48BXUX', 'ID_3KSXSA', 'ID_O3C6LW', 'ID_T6VOCK',\n",
              "       'ID_5XNU0Q', 'ID_XLZX22', 'ID_MCWKH9', 'ID_0R34LV', 'ID_3TZQ7K',\n",
              "       'ID_NAW4CO', 'ID_ESQOEZ', 'ID_1TLRI5', 'ID_84R8D3', 'ID_BBORY0',\n",
              "       'ID_V92P8U', 'ID_D1V241', 'ID_1BV6E3', 'ID_FZWW03', 'ID_LXKOY8',\n",
              "       'ID_Y21SJT', 'ID_GLLYJF', 'ID_PF565I', 'ID_5FQ4L3', 'ID_K30017',\n",
              "       'ID_JFNWDO', 'ID_ZDLVIS', 'ID_T9LPNE', 'ID_GFLA2H', 'ID_0BNC3T',\n",
              "       'ID_GWVVZP', 'ID_JTQ0P7', 'ID_7ZC9Y7', 'ID_8HGFQA', 'ID_6HA3S7',\n",
              "       'ID_OGVA7H', 'ID_KYFQE0', 'ID_1E6WAU', 'ID_5NTPK8', 'ID_UMOMRE',\n",
              "       'ID_TP3UER', 'ID_IVHZY9', 'ID_2UN6UO', 'ID_EHQSUZ', 'ID_64EG2T',\n",
              "       'ID_DNJDDE', 'ID_89TX3M', 'ID_YVJD32', 'ID_7KJDJ1', 'ID_AEGC29',\n",
              "       'ID_I34A3G', 'ID_FQ4042', 'ID_S03VVD', 'ID_FXBS2W', 'ID_SV0WPP',\n",
              "       'ID_QBD4WZ', 'ID_ZDRUPG', 'ID_VLBD78', 'ID_2NHI03', 'ID_5W4S7Z',\n",
              "       'ID_LNFPIG', 'ID_54HKQM', 'ID_SOFSF6', 'ID_0TDC43', 'ID_ZFRXG9',\n",
              "       'ID_4HXIMT', 'ID_OBRIXN', 'ID_6ICOJE', 'ID_745BZG', 'ID_G3I1ZB',\n",
              "       'ID_C757TM', 'ID_WG3P7U', 'ID_I3LAQC', 'ID_963XIM', 'ID_5AZQBP',\n",
              "       'ID_F1I7E3', 'ID_STE5NY', 'ID_9XDYDJ', 'ID_S5N51N', 'ID_J5O6PS',\n",
              "       'ID_WH05N4', 'ID_KP9T9R', 'ID_4EWCGF', 'ID_QZH3NL', 'ID_XWRLKQ',\n",
              "       'ID_3FKI58', 'ID_7GDFJF', 'ID_WZ3TW5', 'ID_6BM9M9', 'ID_77D5US',\n",
              "       'ID_NTQ5IF', 'ID_TFYPPS', 'ID_XOURGN', 'ID_KLNVIK', 'ID_UZDEDJ',\n",
              "       'ID_P1PHZ6', 'ID_ZID82Q', 'ID_27JHSS', 'ID_K1R0NR', 'ID_ODU3RX',\n",
              "       'ID_1T8IFT', 'ID_IPA9DR', 'ID_6EEHDV', 'ID_PTA19A', 'ID_KLHA9S',\n",
              "       'ID_RAUE1N', 'ID_JIGN7R', 'ID_GVJ4G8', 'ID_7GHOOZ', 'ID_KTMTI8',\n",
              "       'ID_SZNIAM', 'ID_FUY2AZ', 'ID_C2N2JS', 'ID_PJV87B', 'ID_C7I8R1',\n",
              "       'ID_N41MO2', 'ID_F0C403', 'ID_Z88REC', 'ID_PN77V2', 'ID_IQNGC7',\n",
              "       'ID_ABE8OF', 'ID_P9P71N', 'ID_UL0S2J', 'ID_LLIKR8', 'ID_PECL8Z',\n",
              "       'ID_91LLZ6', 'ID_3Z67B4', 'ID_GZSF6I', 'ID_PM22QG', 'ID_GSR1A1',\n",
              "       'ID_5XHZ96', 'ID_JHF65M', 'ID_XNZDLE', 'ID_HUHNDM', 'ID_HQKSOW',\n",
              "       'ID_52EYWJ', 'ID_EYLM31', 'ID_58PJ1T', 'ID_FCQKFO', 'ID_CRYIDY',\n",
              "       'ID_Z7ZL5L', 'ID_V025IA', 'ID_HC1DD6', 'ID_4MYBDR', 'ID_YPTSYI',\n",
              "       'ID_UR51G8', 'ID_1O8V9X', 'ID_L9RJOC', 'ID_GOB7J8', 'ID_WT43SE',\n",
              "       'ID_582TCW', 'ID_AT01F2', 'ID_7D7IQW', 'ID_86QUYE', 'ID_URM78L',\n",
              "       'ID_WQ4W5V', 'ID_XO42G3', 'ID_R3S2DG', 'ID_Q8U1UR', 'ID_71TWRL',\n",
              "       'ID_96T6WB', 'ID_XRXNUG', 'ID_WXZZQR', 'ID_0ERLPA', 'ID_MRP71A',\n",
              "       'ID_3N8S29', 'ID_1X388Q', 'ID_UDQ4ZC', 'ID_PT72VJ', 'ID_T1ACS5',\n",
              "       'ID_F8MQ9A', 'ID_V5DAT9', 'ID_QVKHU2', 'ID_G16CEV', 'ID_JYAOJU',\n",
              "       'ID_PXL6N0', 'ID_Y7XVPT', 'ID_X77TDE', 'ID_L3PJWJ', 'ID_UJM1CF',\n",
              "       'ID_RLHBS7', 'ID_07WDAB', 'ID_UJWZ3Z', 'ID_HMAZGU', 'ID_23BDL3',\n",
              "       'ID_W90BW8', 'ID_PW4CQP', 'ID_MGDYEE', 'ID_8F6NKT', 'ID_200VAC',\n",
              "       'ID_SS113N', 'ID_WIYAF5', 'ID_6ZB28D', 'ID_DD17VK', 'ID_6WDWS6',\n",
              "       'ID_5K5OND', 'ID_ZMUYMG', 'ID_IQY07N', 'ID_HJU0OJ', 'ID_B0CSTM',\n",
              "       'ID_VJD0YB', 'ID_P55LTA', 'ID_C8K73S', 'ID_58R9JA', 'ID_LVXA9S',\n",
              "       'ID_28L4UH', 'ID_CUICJX', 'ID_89NZ31', 'ID_GXZPRT', 'ID_WIRUTW',\n",
              "       'ID_GTR00H', 'ID_C0RW46', 'ID_4BRZ8V', 'ID_88MRHC', 'ID_BKA164',\n",
              "       'ID_NH3559', 'ID_648AJG', 'ID_TAE0BX', 'ID_BFV28B', 'ID_W73PHL',\n",
              "       'ID_S61SK2', 'ID_Q50FKM', 'ID_PKL73U', 'ID_0BIFZ1', 'ID_9VR7PW',\n",
              "       'ID_TIKX5G', 'ID_JLF2TF', 'ID_OSISXN', 'ID_2OH3JT', 'ID_NLD6JT',\n",
              "       'ID_NQ7IZL', 'ID_Y8TNCF', 'ID_J14DSA', 'ID_ANZZXJ', 'ID_K01TJI',\n",
              "       'ID_ZAQ8HD', 'ID_C91KSV', 'ID_SZF7CG', 'ID_U7IFQ3', 'ID_6924UZ',\n",
              "       'ID_TCEJQN', 'ID_4QOC2U', 'ID_GM9WH5', 'ID_1JEQ3Y', 'ID_1OMJJF',\n",
              "       'ID_IFZNUC', 'ID_NCQFOI', 'ID_4CL0WA', 'ID_5FCA29', 'ID_WR2UA5',\n",
              "       'ID_JH3N3X', 'ID_CMZG8A', 'ID_V9TMRR', 'ID_TQ3QC7', 'ID_T1RDMN',\n",
              "       'ID_F2756F', 'ID_QPU18V', 'ID_UUBH49', 'ID_HCKQLE', 'ID_X49QML',\n",
              "       'ID_4Q4QLF', 'ID_91NCTL', 'ID_N1652A', 'ID_LWP17I', 'ID_T7I15I',\n",
              "       'ID_K0WGZJ', 'ID_FY9VDV', 'ID_KTFDDC', 'ID_KU0DOH', 'ID_H0ZU7X',\n",
              "       'ID_9WDYSR', 'ID_Q7BJZL', 'ID_O516QA', 'ID_FC2UCJ', 'ID_7T0YJQ',\n",
              "       'ID_071JWN', 'ID_40IVR4', 'ID_TCOEHH', 'ID_2MGU1Y', 'ID_0O0M8R',\n",
              "       'ID_65Z3XC', 'ID_0YLRU0', 'ID_CVUER5', 'ID_1104TL', 'ID_UY91MO',\n",
              "       'ID_1YWYPE', 'ID_4B7MTE', 'ID_CA1LRS', 'ID_H2D9HP', 'ID_II8NPN',\n",
              "       'ID_0NEHH2', 'ID_JE7LAR'], dtype=object)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.image_ids[(kmeans == 4)] # & (all_targets == 0) 2, 3"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "torch1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
